from __future__ import annotations

import base64
import io
import logging
import mimetypes
import os
import time
from pathlib import Path

from PIL import Image, ImageOps

logger = logging.getLogger(__name__)


PROMPT_GUARDRAIL = (
    "请尽可能保持原图构图、视角、主体位置与材质不变，仅根据需求进行最小必要修改，"
    "避免大幅重绘、避免风格突变、避免替换无关元素。"
)


def _iter_response_parts(response):
    parts = getattr(response, "parts", None)
    if parts:
        return parts
    candidates = getattr(response, "candidates", None) or []
    if candidates:
        return getattr(candidates[0].content, "parts", None) or []
    return []


def _image_to_data_url(image_path: Path) -> str:
    mime_type = mimetypes.guess_type(image_path.name)[0] or "image/png"
    return f"data:{mime_type};base64,{base64.b64encode(image_path.read_bytes()).decode('utf-8')}"


def _revise_prompt_with_gpt52(source_image_path: Path, desired_image_prompt: str, model: str = "gpt-5.2") -> str:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return f"{PROMPT_GUARDRAIL}\n\n需求：{desired_image_prompt}"

    try:
        from openai import OpenAI
    except Exception:
        return f"{PROMPT_GUARDRAIL}\n\n需求：{desired_image_prompt}"

    client = OpenAI(api_key=api_key)
    system = (
        "你是住区更新场景的图改图提示词改写专家。"
        "你的任务是：结合用户给出的现场图片和原始文字需求，"
        "将其改写为一段清晰、具体、可实施的中文图像编辑模型提示词（prompt）。"
        "你需要在忠实保留原场景基本结构的前提下，明确说明：哪些元素需要保留，哪些可以新增、移动或移除，以及这样做对通行与安全的影响。"
        "必须强调可实施性：需要考虑对象是否真的可以移动/增建/拆除，是否会挤占过道、占用消防疏散空间、影响视线与出入口安全等。"
        "生成的内容要适合在“基于现有照片进行图像编辑”的模型中直接使用。"
        "只输出最终用于图改图的 prompt 文本，不要输出任何解释、分析或分条列表。"
    )
    user = (
        f"原始需求（来自上一阶段的空间组织描述）：{desired_image_prompt}\n\n"
        "请在理解现场图片的基础上，将上述内容改写为一段可直接用于【在原照片基础上进行编辑】的真实可落地图生图/图改图中文 prompt。"
        "改写时请遵循以下要求：\n"
        f"- 必须遵守以下安全与合规约束：{PROMPT_GUARDRAIL}\n"
        "- 改造应充分考虑现实可行性，不得提出不现实的大拆大改或结构性重建，只做局部空间与设施层面的调整和优化。\n"
        "- 不得堵塞主要通道、出入口和消防通道，不得引入明显安全隐患（如遮挡视线、占用疏散空间、无防护高差等）。\n"
        "- 在 prompt 中用自然语言清楚描述：需要保留的原有元素（建筑、道路、绿化等）、允许调整或新增的元素（如座椅、花池、照明、非机动车位等），"
        "以及这些调整后形成的空间关系和人流动线。避免引入与现场环境明显不符的超现实或科幻元素。\n"
        "- 在风格上应保持与原照片整体视角、构图和时间段（如白天/夜间）大体一致，只对内容和秩序进行优化，而非完全换一个场景。\n"
        "- 输出一段连续的中文描述，用于直接作为图改图模型的 prompt，不要添加任何解释性语句、前后缀或列表符号。"
    )

    try:
        resp = client.responses.create(
            model=model,
            input=[
                {"role": "system", "content": [{"type": "input_text", "text": system}]},
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": user},
                        {"type": "input_image", "image_url": _image_to_data_url(source_image_path)},
                    ],
                },
            ],
            temperature=0.2,
        )
        revised = (resp.output_text or "").strip()
        if revised:
            logger.info("[image_generation] revised prompt generated by gpt-5.2")
            return revised
    except Exception as exc:
        logger.warning("[image_generation] prompt revision failed, fallback to original prompt. err=%s", exc)

    return f"{PROMPT_GUARDRAIL}\n\n需求：{desired_image_prompt}"




def _normalize_image_orientation(img: Image.Image) -> Image.Image:
    """Apply EXIF orientation so portrait/landscape is consistent before concat."""
    return ImageOps.exif_transpose(img).convert("RGB")

def _part_to_image(part) -> Image.Image | None:
    if not (getattr(part, "inline_data", None) and getattr(part.inline_data, "data", None)):
        return None

    data = part.inline_data.data
    if isinstance(data, (bytes, bytearray)):
        image_bytes = bytes(data)
    else:
        image_bytes = base64.b64decode(data)

    # Preferred path: decode inline bytes directly.
    try:
        return _normalize_image_orientation(Image.open(io.BytesIO(image_bytes)))
    except Exception:
        # Fallback for SDK variants/mocks where inline bytes are placeholders but
        # `part.as_image()` returns a valid image object.
        as_img = getattr(part, "as_image", None)
        if callable(as_img):
            obj = as_img()
            if hasattr(obj, "save"):
                if isinstance(obj, Image.Image):
                    return _normalize_image_orientation(obj)
                buf = io.BytesIO()
                obj.save(buf, format="PNG")
                buf.seek(0)
                return _normalize_image_orientation(Image.open(buf))
        raise


def _concat_side_by_side(original_image: Image.Image, edited_image: Image.Image) -> Image.Image:
    # Keep same height for side-by-side concat: old on left, new on right.
    target_h = max(original_image.height, edited_image.height)

    def resize_to_h(img: Image.Image, h: int) -> Image.Image:
        if img.height == h:
            return img
        w = max(1, int(img.width * (h / img.height)))
        return img.resize((w, h), Image.Resampling.LANCZOS)

    left = resize_to_h(_normalize_image_orientation(original_image), target_h)
    right = resize_to_h(_normalize_image_orientation(edited_image), target_h)

    canvas = Image.new("RGB", (left.width + right.width, target_h), color=(255, 255, 255))
    canvas.paste(left, (0, 0))
    canvas.paste(right, (left.width, 0))
    return canvas


def edit_image_with_gemini_nanobanana_with_prompt(
    prompt: str,
    source_image_path: str | Path,
    output_path: str | Path,
    model: str = "gemini-3-pro-image-preview",
) -> tuple[str, str]:
    """Image-to-image editing via Gemini image generation API.

    Returns (saved_path, revised_prompt).
    Saves a side-by-side comparison image: original(left) + edited(right).
    """
    logger.info("[image_generation] start edit model=%s source=%s", model, source_image_path)
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY or GOOGLE_API_KEY is required for Gemini image editing")

    source_image_path = Path(source_image_path)
    if not source_image_path.exists():
        raise FileNotFoundError(f"Source image not found: {source_image_path}")

    try:
        from google import genai
        from google.genai import types
    except Exception as exc:  # pragma: no cover
        raise ImportError("Install `google-genai` to use Gemini image editing") from exc

    client = genai.Client(api_key=api_key)
    img_bytes = source_image_path.read_bytes()
    mime_type = mimetypes.guess_type(source_image_path.name)[0] or "image/png"

    revised_prompt = _revise_prompt_with_gpt52(source_image_path, prompt, model="gpt-5.2")

    response = None
    last_exc: Exception | None = None
    for attempt in range(1, 6):
        try:
            response = client.models.generate_content(
                model=model,
                contents=[
                    types.Part.from_text(text=revised_prompt),
                    types.Part.from_bytes(data=img_bytes, mime_type=mime_type),
                ],
                config=types.GenerateContentConfig(
                    response_modalities=["IMAGE"],
                    image_config=types.ImageConfig(image_size="2K"),
                ),
            )
            break
        except Exception as exc:
            last_exc = exc
            wait_s = min(2 ** (attempt - 1), 8)
            logger.warning(
                "[image_generation] Gemini request failed attempt=%s/5 wait=%ss err=%s",
                attempt,
                wait_s,
                exc,
            )
            if attempt < 5:
                time.sleep(wait_s)

    if response is None:
        raise RuntimeError(f"Gemini request failed after retries: {last_exc}") from last_exc

    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    original = _normalize_image_orientation(Image.open(source_image_path))
    for part in _iter_response_parts(response):
        if getattr(part, "text", None):
            logger.info("[image_generation] Gemini text response: %s", part.text)

        edited = _part_to_image(part)
        if edited is not None:
            merged = _concat_side_by_side(original, edited)
            merged.save(output_path)
            logger.info("[image_generation] saved side-by-side image -> %s", output_path)
            return str(output_path), revised_prompt

    raise RuntimeError("Gemini did not return an edited image payload")



def edit_image_with_gemini_nanobanana(
    prompt: str,
    source_image_path: str | Path,
    output_path: str | Path,
    model: str = "gemini-3-pro-image-preview",
) -> str:
    saved_path, _ = edit_image_with_gemini_nanobanana_with_prompt(
        prompt=prompt,
        source_image_path=source_image_path,
        output_path=output_path,
        model=model,
    )
    return saved_path
